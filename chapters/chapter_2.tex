\mbox{}\\
\vspace{8cm}

This chapter is a reproduction of the following article:

R. Mamede, P. Vila-Cerqueira, J. A. Carriço, M. Ramirez. chewBBACA 3: lowering the barrier for scalable and detailed whole- and core-genome multilocus sequence typing. (2025). [Manuscript submitted for publication].

The supplementary material referred to throughout the text can be consulted in the last section of this chapter, \textbf{\autoref{sec:ch2_supplemental_material}}.

As mentioned in \textbf{\autoref{ch:introduction}}, \ac{wg/cgMLST} approaches have been increasingly adopted by research and public health institutions for surveillance, outbreak detection and characterization, and for the study of the population diversity of bacterial pathogens, especially of \ac{FWD} pathogens. Since \ac{wg/cgMLST} is an expansion of the classical seven-gene \ac{MLST}, it is conceptually and technically easier to implement and standardize. However, the successful integration of \ac{wg/cgMLST} is not without challenges. Firstly, as more and more sequencing data becomes available, it is clear that \ac{wg/cgMLST} methods need to be continuously improved to ensure the level of efficiency necessary to process larger volumes of data. Secondly, while we can determine the complete or nearly complete genome sequence of bacterial pathogens, most approaches focus only on the core genome (i.e., \ac{cgMLST}). The core genes are present in all or most strains and generally display lower sequence diversity than the accessory genes, enabling the definition of stable \ac{cgMLST} schemas that provide good resolution. However, while robust, \ac{cgMLST} ignores the diversity of the accessory genome and may not offer enough resolution for outbreak-level strain discrimination. Lastly, currently there is no \ac{wg/cgMLST} tool or platform that offers scalable and decentralized schema creation, allele calling, and comprehensive analysis of the results, which may hinder efforts for the global adoption of \ac{wg/cgMLST}, especially in cases where computational resources are limited and for users who lack bioinformatics training.

This chapter describes the main features of chewBBACA 3, a suite of modules developed for scalable and comprehensive \ac{wg/cgMLST}. chewBBACA 3 is a complete reimplementation of the first published version of chewBBACA. By developing chewBBACA 3, I continued to support a widely used tool that was initially developed in the lab where the work presented in this thesis was carried out and had the opportunity to tackle some of the challenges related to \ac{wg/cgMLST} referenced above. The results presented in this chapter highlight the efficiency and accuracy of the schema creation and allele call processes with chewBBACA 3, which enable fast large-scale analysis on a laptop. In addition, the modules for comprehensive schema and allele call results analysis included in chewBBACA 3 make it a complete solution for \ac{wg/cgMLST} in surveillance and outbreak investigation settings, as well as for population studies.

The contributions of the other authors and the suggestions provided by users have been instrumental in the continuous improvement of chewBBACA. I have been maintaining and actively improving chewBBACA since 2020 to build a tool for \ac{wg/cgMLST} that considerably reduces computational requirements for large-scale \ac{wg/cgMLST}, enables users to create schemas that capture more of the diversity of bacterial species to go beyond \ac{cgMLST}, and provides analytic capabilities that help to explore results and reach an informed decision. As the main contributor, I have been involved in all aspects of the development of chewBBACA 3 and on the study design, data analysis, and writing related to the results presented in this chapter.

\newpage

\begin{center}
\large
\textbf{chewBBACA 3: lowering the barrier for scalable and detailed whole- and core-genome multilocus sequence typing}
\end{center}

Rafael Mamede$^{1,2}$, 
Pedro Vila-Cerqueira$^{1}$,
João André Carriço$^{1}$,
Mário Ramirez$^{1}$

$^1$ Instituto de Microbiologia, Instituto de Medicina Molecular, Faculdade de Medicina, Universidade de Lisboa, Portugal;

$^2$ Gulbenkian Institute for Molecular Medicine.

\section{Abstract} \label{sec:ch2_abstract}

\subsection{Background} \label{ssec:ch2_abstract_background}

The wide adoption of whole genome sequencing has enabled the implementation of genomics-based systems, which provide unparalleled resolution for the surveillance and outbreak investigation of bacterial pathogens. To fully exploit the wealth and complexity of genomics data, bioinformatics methods need to be highly scalable, provide accurate and extensive data for potential downstream analyses, as well as analytic capabilities. Here, we present chewBBACA 3, a suite of modules for scalable and comprehensive bacterial \ac{wg/cgMLST} with built-in features to create new schemas, evaluate loci diversity and strain similarity.

\subsection{Results} \label{ssec:ch2_abstract_results}

chewBBACA 3 enables faster and more accurate schema creation and allele calling by complementing an alignment-based approach with alignment-free methods, including hash-based comparisons and minimizer-based clustering. Schema creation is up to 55-fold faster and identifies up to 10\% more loci than its predecessor, chewBBACA 2. Furthermore, chewBBACA 3 can quickly adapt or import schemas available on external \ac{wg/cgMLST} platforms or Chewie-NS, promoting interoperability. The efficiency of allele calling allows processing larger genome collections, from thousands to tens of thousands of genomes, at the whole- and core-genome levels without requiring high computational resources and being up to 52-fold faster than similar tools. chewBBACA 3’s enhanced sensitivity allows it to identify and classify more schema loci and coding sequences than the compared methods, resulting in higher resolution for strain comparison. Moreover, the allelic profiles, classification statistics and associated sequence data produced by chewBBACA 3 can be the basis for detailed analyses that provide added value in surveillance and outbreak investigation settings. New modules leverage the potential of the schema and allele call results data to create interactive reports that enable an intuitive and in-depth analysis of allele diversity in loci of interest and allow assessing strain similarity based on loci presence, allelic distances and phylogenetic analysis.

\subsection{Conclusions} \label{ssec:ch2_abstract_conclusions}

chewBBACA 3 provides functionalities for complete \ac{wg/cgMLST} analysis at scale, lowering the barrier for the use of \ac{wg/cgMLST} and offering extensive results and analytic capabilities for streamlined, comprehensive, and local analyses. chewBBACA 3 is freely available at \url{https://github.com/B-UMMI/chewBBACA}.

\section{Background} \label{sec:ch2_background}

The burden of bacterial infections constitutes a major challenge to public health systems worldwide \citep{ikuta_global_2022, noauthor_who_2024}. The advances in sequencing technologies have enabled public health institutions to support and gradually transition to whole genome sequencing (\ac{WGS}), increasing surveillance capacity and the effectiveness of outbreak investigations. \ac{WGS} offers high-resolution discrimination of closely related bacterial strains and enables the identification of pathogens’ relevant features in a timely and accurate manner, aiding in reaching an informed decision for effective disease prevention and control \citep{authority_efsa_efsa_2024, struelens_real-time_2024, european_centre_for_disease_prevention_and_control_ecdc_2019, authority_efsa_guidelines_2022}. The widespread use of \ac{WGS}, as well as the adherence to \ac{FAIR} principles, encouraged the development of efficient bioinformatics methods for in silico \ac{MLST}, serotyping, and the identification of antimicrobial resistance and virulence determinants. It also allowed transitioning to methods with enhanced resolution that leverage the full genomic content to identify relevant features and provide a more accurate measure of strain similarity \citep{uelze_typing_2020}.

These methods are diverse but generally adopt one of three fundamental approaches: i) determining \ac{SNVs} relative to a reference genome, ii) measuring sequence similarity based on short subsequences of length k, known as k-mers, and iii) comparing the strains' gene content, referred to as \ac{GbG} methods \citep{uelze_typing_2020}.

\ac{SNV} approaches detect differences at the single nucleotide level by mapping sequencing reads against a closely related reference strain. The precision level of this approach enables the identification of point mutations or more complex variants that can be determinants of phenotypic characteristics of interest, such as increased virulence and antimicrobial resistance. The choice of the reference genome is crucial as the quality and relatedness of the reference genome to the strains of interest can greatly influence the number of shared positions compared and, therefore, the extent of the variability detected \citep{bush_genomic_2020, valiente-mullor_one_2021}. k-mer-based tools split genomic sequences into k-mers and compare the resulting k-mer sets to estimate strain similarity or identify regions of interest. These approaches can estimate similarity without needing a reference genome and are potentially faster and more computationally efficient than \ac{SNV} or \ac{GbG} approaches. The efficiency of these approaches depends on the sampling method used to select k-mers, which should be fine-tuned to achieve a good balance between efficiency and accuracy for the desired application \citep{ndiaye_when_2024, belbasi_minimizer_2022}. With the wide adoption of \ac{WGS}, \ac{GbG} approaches have transitioned from classical \ac{MLST} to \ac{wg/cgMLST}. \ac{wg/cgMLST} enables the creation of schemas encompassing the variability of hundreds to thousands of loci for a species of interest to accurately determine the loci and alleles present in strains of interest. Creating and maintaining \ac{wg/cgMLST} schemas to capture a species' diversity is crucial for the accuracy of \ac{GbG} methods and can be a laborious process. As with \ac{SNV} approaches, knowing the alleles present at a given locus can be linked to phenotypic properties such as virulence or antimicrobial resistance.

It has been shown that applying any of these approaches can generate results suitable for accurate strain similarity estimation and phylogenetic analyses in surveillance and outbreak scenarios \citep{uelze_typing_2020, bush_genomic_2020, valiente-mullor_one_2021, ndiaye_when_2024, belbasi_minimizer_2022, king_comparison_2024}. Nevertheless, \ac{wg/cgMLST} has been more frequently integrated into surveillance and outbreak detection systems, partly due to constituting an expansion of classical \ac{MLST}, which conceptually and technically allows for a more straightforward implementation, specially in constantly growing datasets such as the ones used in long-term epidemiological surveillance. The capacity to update \ac{wg/cgMLST} schemas with new alleles increases the diversity captured by and, consequently, the resolution of \ac{wg/cgMLST} analyses. Moreover, \ac{wg/cgMLST} allows establishing allelic nomenclatures for standardised comparisons. Existing solutions for \ac{wg/cgMLST} analysis can vary greatly in the degree of data centralisation, analytical capabilities, and license type \citep{jolley_bigsdb_2010, zhou_enterobase_2020, mamede_chewie_2021}. To continue to promote the adoption of \ac{wg/cgMLST}, improvements should focus on interoperability to facilitate comparison of results, scalability to meet growing data processing demands, and easily performed comprehensive local analyses to offer powerful analytic capabilities to end users while complying with strict data privacy laws.

To provide a solution for scalable, detailed, and local \ac{wg/cgMLST}, we developed chewBBACA 3, which vastly improves and extends the functionalities of chewBBACA 2 \citep{mamede_chewie_2021, silva_chewbbaca_2018}, a widely used tool for \ac{wg/cgMLST} which has been integrated into public health workflows such as the \ac{EFSA} One Health \ac{WGS} system, used for rapid detection of multi-country foodborne outbreaks in collaboration with the \ac{ECDC} \citep{authority_efsa_guidelines_2022}.

\section{Implementation} \label{sec:ch2_implementation}

\subsection{Overview} \label{ssec:ch2_implementation_overview}

chewBBACA 3 is a complete reimplementation of its predecessor, chewBBACA 2 \citep{mamede_chewie_2021}, which was already an upgraded version of chewBBACA’s first published version \citep{silva_chewbbaca_2018}. chewBBACA 3 provides a modular approach for complete \ac{wg/cgMLST} analysis allowing more efficient and accurate schema creation and allele calling and offering interactive reports for comprehensive schema and results analyses (Figure \ref{fig:chap2_figure1_legend}). chewBBACA 3 allows to set up schemas for \ac{wg/cgMLST} through the use of larger collections of genome assemblies or \ac{CDSs} in FASTA format or by adapting existing schemas from external platforms \citep{jolley_bigsdb_2010, zhou_enterobase_2020, noauthor_cgmlstorg_nodate}. Additionally, the integration with Chewie-NS, which was previously described together with chewBBACA 2 \citep{mamede_chewie_2021}, allows easily importing ready-to-use schemas to obtain comparable interlaboratory results based on a common allelic nomenclature. To determine the allelic profiles of strains of interest, chewBBACA 3 identifies and clusters the distinct CDSs predicted from the strains' genomes, significantly reducing the number of comparisons against the schema loci in contrast to the sequential strain processing used by chewBBACA 2. This translates into faster and more efficient allele calling and facilitates data aggregation to create output files with more detailed results. Allele calling identifies and adds new alleles to schemas, ensuring that they are gradually updated to produce accurate and comparable results over time. Similarly to chewBBACA 2, new alleles are inferred based on the \ac{BSR} \citep{rasko_visualization_2005} computed from \ac{BLASTp} alignments \citep{camacho_blast_2009}, complying with minimum sequence length and allele size variation thresholds \citep{silva_chewbbaca_2018}. Adjustments to these parameters allow chewBBACA 3 to classify more \ac{CDSs} and capture loci diversity more accurately. chewBBACA 3 increases the granularity of the results by expanding the set of special classifications assigned when the presence of a locus cannot be inferred confidently, such as when a \ac{CDS} matching a schema locus is outside the user-specified locus size variation interval or if multiple \ac{CDSs} from a genome match the same schema locus (Figures \ref{fig:chap2_figureS1}-\ref{fig:chap2_figureS4}). These special classifications aid in identifying spurious alleles resulting from low-quality data, pseudogenes, and paralogous loci. The set of core loci can be determined based on the allele calling results for any locus presence threshold, and the resulting list of core loci can be used to perform allele calling at the core genome level. Schema loci can be annotated by searching for matches through UniProt’s \ac{SPARQL} endpoint, which was already an option in chewBBACA 2, and now also by aligning a schema’s alleles against UniProt’s reference proteomes to retrieve annotations based on higher-quality entries \citep{the_uniprot_consortium_uniprot_2025}. New schema and results evaluation modules leverage the power of the React JavaScript library \citep{noauthor_react_nodate} to build interactive reports that enable local and comprehensive analyses of the diversity of loci contained in schemas and aid in identifying closely related strains for more effective surveillance and outbreak assessment.

\subsection{Core modules} \label{ssec:ch2_implementation_core_modules}

While all the modules in chewBBACA 2 were reimplemented to increase the scalability and comprehensiveness of the results generated by chewBBACA 3, module development concentrated primarily on the \textit{CreateSchema} and \textit{AlleleCall} modules (Figures \ref{fig:chap2_figureS5} and \ref{fig:chap2_figureS6}), which handle schema creation and allele calling, respectively. Gene prediction was optimised in both modules using Pyrodigal \citep{larralde_pyrodigal_2022, hyatt_prodigal_2010}, a Python module that provides bindings to Prodigal for seamless integration and offers several advantages, such as faster gene prediction and greater control over gene prediction parameters and results. Additionally, a novel feature was added allowing both modules to accept FASTA files with \ac{CDSs}, enabling users to leverage the vast \ac{CDS} data available in public databases or provide \ac{CDSs} predicted by other gene prediction tools if preferred by the user, such as GeneMarkS-2 or Balrog \citep{lomsadze_modeling_2018, sommer_balrog_2021}. Following the gene prediction step, \ac{CDS} deduplication is performed at both \ac{DNA} and protein levels to identify the set of distinct \ac{CDSs}. The distinct translated \ac{CDSs} are clustered based on the proportion of shared minimizers ($\geq0.2$) with representative alleles \citep{schleimer_winnowing_nodate, roberts_reducing_2004, marcais_improving_2017} (Figure \ref{fig:chap2_figure1_legend}B:1-3). The minimizer parameters (k=5, w=5, lexicographic order) were chosen to select sets of k-mers that would cover most sequence positions at least once while also keeping memory usage low \citep{zheng_improved_2020}. The low clustering threshold groups similar sequences into the same clusters, reducing the number of comparisons in subsequent steps. For schema creation, the \ac{CDSs} sharing a high proportion of minimizers ($\geq0.9$) with the cluster representative or larger \ac{CDSs} are considered alleles of the same locus and are excluded (Figure \ref{fig:chap2_figure1_legend}B:4). The clustering results are complemented by intracluster and intercluster alignment with \ac{BLASTp} to exclude \ac{CDSs} based on the \ac{BSR} threshold and select the final set of \ac{CDSs} (Figure \ref{fig:chap2_figure1_legend}B:5). This defines the schema by creating a schema seed with one representative allele for each locus. This schema seed will be used by the \textit{AlleleCall} module, which may add further representative alleles to capture the allelic diversity at each locus. The \textit{AlleleCall} module uses the same functions as the schema creation process for sequence deduplication and \ac{CDS} clustering. Another novel feature implemented is that each distinct \ac{CDS} is hashed, mapped to the compressed list of genomes that contain it (Figure \ref{fig:chap2_figureS7}) and compared against the hashed schema alleles. This allows keeping the information about the \ac{CDSs} identified in all strains in memory, enabling fast exact matching and classification of all genomes containing a \ac{CDS} based on a single match. Clustering and intracluster alignment with \ac{BLASTp} allow comparison of the remaining unclassified \ac{CDSs} against the schema's representative alleles to find and classify inexact matches (Figure \ref{fig:chap2_figure1_legend}B:1-4). A final step aligns the schema's representative alleles against the remaining unclassified \ac{CDSs} to find more divergent alleles and select new representative alleles (Figure \ref{fig:chap2_figure1_legend}B:5). The matches found throughout the process are evaluated at the end of the process to assign the final classifications, create the allelic profiles, and update the schema with novel alleles. Both core modules create several output files with detailed schema and results data that support the analyses performed by other modules and can serve as the basis for custom analyses that seek to answer relevant questions at the strain or population-wide level.
A more detailed description of the implementation and functionalities included in each module is available in the supplementary material and in chewBBACA’s online documentation \citep{noauthor_chewbbaca_nodate}.

\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,height=0.92\textheight]{figures/chapter 2/Figure1.pdf}
    \label{fig:chap2_figure1}
\end{figure*}
\vspace*{-6mm}
\begin{center}
    \emph{(Caption on next page.)}
\end{center}
\begin{figure*}[h!]
    \caption[Overview of chewBBACA 3’s processes and minimizer-based clustering used by the \textit{CreateSchema} and \textit{AlleleCall} modules.]{Overview of chewBBACA 3’s processes and minimizer-based clustering used by the \textit{CreateSchema} and \textit{AlleleCall} modules. (A) chewBBACA 3 includes modules for schema setup (steps labeled with 1, 2 and 3), allele calling (steps labeled with 4), core genome determination (steps labeled with 5), schema annotation (steps labeled with 6), schema evaluation (steps labeled with 7), and results evaluation (steps labeled with 8). Blue cylinder icons represent schemas, with the central cylinder icon representing a schema created or adapted for usage with chewBBACA 3. Green document icons represent input FASTA files. Grey rectangle icons represent analysis processes available in chewBBACA 3. (B) Minimizer-based clustering and classification steps implemented in the \textit{CreateSchema} and \textit{AlleleCall} modules. (Step 1) The distinct translated \ac{CDSs} not classified through exact matching at the \ac{DNA} and protein levels are sorted based on decreasing size. (Step 2) Minimizers are selected from the set of 5-mers for each \ac{CDS} based on lexicographic order and a window size of 5. (Step 3) The set of minimizers selected for each \ac{CDS} is compared against the minimizers of \ac{CDSs} selected as cluster representatives (\textit{CreateSchema}) or the schema loci representative alleles (\textit{AlleleCall}) to cluster \ac{CDSs} based on a proportion of shared minimizers $\geq0.2$. (Step 4) The \ac{CDSs} that share a proportion of minimizers $\geq0.9$ (\textit{CreateSchema}) or a \ac{BSR} $\geq0.7$ (AlleleCall) with the cluster representative are excluded from the analysis (\textit{CreateSchema}) or classified (\textit{AlleleCall}). (Step 5) Non-representative \ac{CDSs} from the same cluster are compared to exclude smaller \ac{CDSs} that share a proportion of minimizers $\geq0.9$ with larger \ac{CDSs} (\textit{CreateSchema}). Representative \ac{CDSs} or alleles are aligned against all \ac{CDSs} to exclude (\textit{CreateSchema}) or classify (\textit{AlleleCall}) \ac{CDSs} based on a default \ac{BSR} value of 0.6.}\label{fig:chap2_figure1_legend}
\end{figure*}

\section{Results and discussion} \label{sec:ch2_results_and_discussion}

\subsection{Fast wg/cgMLST schema creation or retrieval from multiple sources} \label{ssec:ch2_results_discussion_ssec1}

chewBBACA 3 offers three options for setting up a schema for \ac{wg/cgMLST} analysis.

The first option is creating a new schema by selecting loci from a set of complete or draft genome assemblies with the \textit{CreateSchema} module to create a schema seed (Figure \ref{fig:chap2_figureS5}). To evaluate the performance of the \textit{CreateSchema} module, we created schema seeds with chewBBACA 3 and chewBBACA 2 based on the complete genome assemblies available on the \ac{NCBI} RefSeq database \citep{sayers_database_2022} for three bacterial species: \textit{Streptococcus pyogenes} (n=260), \textit{Listeria monocytogenes} (n=309), and \textit{Salmonella enterica} (n=1,326). Schema seed creation was 25- to 55-fold faster with chewBBACA 3 than with chewBBACA 2, with similar memory usage (Table \ref{tab:ch2_tableS1}). A comparison of the schema seeds generated with both versions revealed that the schema seeds created by chewBBACA 3 contained 98\% of the loci identified by chewBBACA 2 (Table \ref{tab:ch2_tableS2}). Moreover, chewBBACA 3 identified 6\% to 10\% more loci than chewBBACA 2, primarily due to a more accurate identification of smaller loci. Ideally, target loci should be defined based on a set of high-quality genome assemblies to avoid the inclusion of spurious loci in the schema seed. Nonetheless, schema seed creation with chewBBACA 3 will remain efficient even when using larger genome collections, possibly including draft genomes, to adequately capture a species diversity.

A second option is to adapt schemas from external platforms with the \textit{PrepExternalSchema} module (Figure \ref{fig:chap2_figureS8}). This module filters out incomplete alleles (i.e. alleles that contain ambiguous bases or not corresponding to valid \ac{CDSs}, such as having no start/stop codon) and selects representative alleles based on a \ac{BSR} threshold to create a schema structure compatible with chewBBACA. Schema adaptation promotes the usage of schemas previously made available and adopted by the community, contributing to the integration and interoperability with other platforms. chewBBACA 3 is over three orders of magnitude faster than chewBBACA 2 when adapting the \ac{cgMLST} schemas for \textit{S. pyogenes}, \textit{L. monocytogenes}, and \textit{S. enterica} available on the cgMLST.org server \citep{noauthor_cgmlstorg_nodate}, adapting any of the schemas in under five minutes (Table \ref{tab:ch2_tableS3}). Furthermore, contrarily to chewBBACA 2, chewBBACA 3 now ensures that the selected representative alleles fully capture the diversity of each locus based on the specified \ac{BSR} threshold (Table \ref{tab:ch2_tableS4}). chewBBACA 3 also provides options to filter out alleles based on user-defined sequence size and size variation thresholds and outputs detailed information about the changes made while adapting a schema to inform the user of the changes introduced to the existing schema.

Lastly, the third option is the \textit{DownloadSchema} module (Figure \ref{fig:chap2_figureS9}), one of the modules (Figures \ref{fig:chap2_figureS9}-\ref{fig:chap2_figureS11}) developed to integrate with Chewie-NS \citep{mamede_chewie_2021}, allowing users to import ready-to-use schemas from Chewie-NS instances. This option offers the advantage of enabling local and private analysis based on a common allelic nomenclature to facilitate the comparison of results. Schemas downloaded from Chewie-NS can be kept up-to-date by synchronizing with the remote versions to receive the latest allele data submitted by other users and, if desired, contribute novel alleles identified locally.

\subsection{Scalable and efficient allele calling} \label{ssec:ch2_results_discussion_ssec2}

We performed allele calling with the schema seeds created with chewBBACA 3 in the previous section and the complete genomes for each species to add new alleles to the schemas and determine the set of core loci with the \textit{ExtractCgMLST} module (Figure \ref{fig:chap2_figureS12}). The lists of core loci (present in 100\% of the genomes) were used to measure performance at the \ac{cgMLST} level for datasets including between 1 and 16,384 draft genome assemblies and compared against the results obtained with chewBBACA 2 and pyMLST \citep{biguenet_introduction_2023} for equivalent schemas and databases (Table \ref{tab:ch2_tableS5}). chewBBACA 3 processed all datasets faster than chewBBACA 2 and pyMLST. On average, chewBBACA 3 was 1.9- to 20.3-fold and 1.3- to 51.9-fold faster than chewBBACA 2 and pyMLST, respectively (Figure \ref{fig:chap2_figure2}A and Table \ref{tab:ch2_tableS6}). The difference increased with dataset size, largely due to the increased redundancy (same sequence found in different genomes) of the set of \ac{CDSs} extracted from the genomes (Table \ref{tab:ch2_tableS7}). For example, only 1.5\% to 2.8\% of the total \ac{CDSs} identified in the complete datasets (n=16,384) were distinct. By identifying the set of distinct \ac{CDSs} before trying to match them against the schema loci, chewBBACA 3 avoids the repeated evaluation of identical \ac{CDSs} identified in multiple genomes.

\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=0.93\textwidth]{figures/chapter 2/Figure2.pdf}
    \caption[Performance comparison of chewBBACA 3, chewBBACA 2 and pyMLST.]{Performance comparison of chewBBACA 3, chewBBACA 2 and pyMLST. (A) Runtime and peak memory usage comparison for the allele calling of datasets with a varying number of genomes (from 1 to 16,384) for three bacterial species: \textit{Streptococcus pyogenes}, \textit{Listeria monocytogenes}, and \textit{Salmonella enterica}. The benchmark was performed with five replicates per dataset size, except for the complete dataset (n=16384). The values shown are the mean of the replicate values for each dataset. Runtime was measured as the elapsed real time in minutes (logarithmic scale). Peak memory usage was measured as the maximum resident set size in \ac{MB} (logarithmic scale). (B) Proportion of strain \ac{CDSs} and schema loci classified for the complete datasets (n=16384). The proportion of classified \ac{CDSs} corresponds to the number of \ac{CDSs} classified by each tool divided by the total number of \ac{CDSs} predicted for each strain by Pyrodigal. The proportion of classified loci corresponds to the number of schema loci identified by each tool divided by the total number of schema loci.}
    \label{fig:chap2_figure2}
\end{figure*}

Additionally, the novel minimizer-based clustering matches the remaining \ac{CDSs} to the most similar schema loci, reducing comparisons between dissimilar sequences. These two steps contribute the most to the increased speed compared to chewBBACA 2 and pyMLST, which process each genome separately and additionally do not take advantage of multiprocessing settings as efficiently as chewBBACA 3. Regarding peak memory usage (Figure \ref{fig:chap2_figure2}A and Table \ref{tab:ch2_tableS8}), chewBBACA 3 used, on average, 8.6- to 1.1-fold more memory than chewBBACA 2 for datasets with up to 1,024 strains. The inverse was observed for larger datasets, with chewBBACA 2 using 1.1- to 6.9-fold more memory than chewBBACA 3. Compared to pyMLST, chewBBACA 3 used 3.1- to 40-fold more memory. pyMLST maintains low memory usage irrespective of dataset size but is single-threaded and only supports the addition of one strain per command, which limits its scalability. chewBBACA 3 enables considerably faster analyses while keeping memory usage in check to allow large-scale analysis without needing high-performance computing infrastructures. While comparing results using the entire \ac{wgMLST} schema would further highlight chewBBACA 3’s efficiency and accuracy, time and memory constraints related to running chewBBACA 2 and pyMLST under the same conditions invalidated such comparison.

The thoroughness of the allele calling in chewBBACA 3 can be controlled through four execution modes (Figure \ref{fig:chap2_figureS6}). Mode 1 identifies exact matches at the \ac{DNA} level between the genomes’ \ac{CDSs} and the schema alleles. Mode 2 adds exact matching at the protein level, enabling the identification of novel alleles with synonymous substitutions. Mode 3 proceeds to clustering and intracluster alignment to identify similar alleles based on the \ac{BSR} threshold. Mode 4, the default, runs the complete process to classify as many \ac{CDSs} as possible and potentially selects new representative alleles, preparing the schema to better identify future novel alleles. Modes 1 and 2 offer a 4.7-fold speedup over the default mode (Figure \ref{fig:chap2_figureS13} and Tables \ref{tab:ch2_tableS9} and \ref{tab:ch2_tableS10}), but their capacity for allele identification is limited to only modestly divergent alleles. This makes them appropriate for applications where a less accurate but much faster strain discrimination is sufficient, or for faster allele calling with schemas that already capture most of a species’ diversity for the set of loci that make up those schemas, as is the case for many publicly available \ac{cgMLST} schemas. Mode 3 provides similar accuracy to the default mode in less time, with a more significant reduction in runtime for larger schemas and more diverse datasets. Mode 4 offers greater sensitivity to identify the most divergent alleles and select new representative alleles to add to schemas, which is essential to increase the diversity captured by a schema, especially in the initial phase of schema development. For schemas that already include representative alleles that capture a species diversity, Mode 3 and Mode 4 may only differ in the number of special classifications attributed, with Mode 4 identifying more.

chewBBACA 2 added new alleles to schemas automatically, not providing any option for users to prevent the allele call process from changing an existing schema. chewBBACA 3 includes the \textit{-{}-no-inferred} option to control this behaviour. This option can be helpful in several scenarios, including: updating schemas only periodically, in applications where frequent schema updates can compromise the reproducibility of the allele calling; classifying genomes from closely related species to identify similar loci; and avoiding adding spurious alleles to a schema when there's uncertainty about the quality level of the genome assemblies being analyzed.

\subsection{Comprehensive allele calling for more accurate and detailed results} \label{ssec:ch2_results_discussion_ssec3}

We evaluated the allele calling results for the complete dataset of each of the three species chosen (consisting of 16,384 genomes) to measure the comprehensiveness of chewBBACA 3's results and compare it against chewBBACA 2 and pyMLST. Results were compared at the core and accessory genome levels, based on a locus presence threshold of 95\%, of the \ac{cgMLST} schemas defined above. Concordance was measured by comparing the pairwise Jaccard distances computed based on the allelic profiles. The core and accessory loci sets determined based on chewBBACA 3’s and chewBBACA 2’s results were highly similar, sharing over 99\% and 95\% of the loci at the core and accessory levels, respectively (Table \ref{tab:ch2_tableS11}). The pairwise Jaccard distances were strongly correlated and near the identity line, indicating high concordance between the results (Figure \ref{fig:chap2_figure3}), with the pairwise allelic distances computed by both tools differing by 0 to 6 differences on average (Figure \ref{fig:chap2_figureS14}). The core loci sets determined based on pyMLST’s results were considerably smaller, containing 42\% to 80\% of the schema loci, compared to over 94\% for chewBBACA 3. The reduced number of core loci identified by pyMLST is related to an inconsistent identification of some loci in each species. This is partly due to the default identity and coverage thresholds used by pyMLST, which are more stringent than the default \ac{BSR} threshold used by chewBBACA and do not allow for the same degree of allele sequence variability. Moreover, pyMLST uses a single representative allele per locus to search for matches, whereas chewBBACA 3 can add new representative alleles to schemas to better capture locus diversity. pyMLST's accessory loci sets were 4- to 11-fold larger than chewBBACA 3's (Table \ref{tab:ch2_tableS11}). The accessory pairwise Jaccard distances were weakly correlated, except for \textit{S. pyogenes}, and the pairwise allelic distances differed by 49 to 141 differences on average. While chewBBACA 2 generates highly comparable results to chewBBACA 3, pyMLST yields considerably different loci sets and pairwise distances, indicating it is not easily comparable to chewBBACA 3. This highlights the importance of the choice of method for \ac{wg/cgMLST} and how the differences detected and distance thresholds defined by different methods may not be equivalent.

chewBBACA 3 classified a similar number of \ac{CDSs} than chewBBACA 2 for \textit{S. pyogenes} and 1.8\% and 0.7\% more \ac{CDSs} for \textit{L. monocytogenes} and \textit{S. enterica}, corresponding to an average of 56 and 33 more \ac{CDSs} per strain (Figure \ref{fig:chap2_figure2}B and Table \ref{tab:ch2_tableS12}). chewBBACA 3 classified 10\% to 35\% more \ac{CDSs} than pyMLST, 177 to 1078 more \ac{CDSs} per strain, on average. chewBBACA 3 and chewBBACA 2 identified over 99\% of the schema loci in all strains, while pyMLST identified between 58\% and 87\% loci (Figure \ref{fig:chap2_figure2}B). Running chewBBACA 3 in mode 3 provided nearly identical results to the default mode. Modes 1 and 2 classified 4\% to 6\% fewer \ac{CDSs} and identified 6\% to 7\% fewer loci than the default mode, respectively, performing worse if many of the strains’ alleles were not equal or highly similar to the alleles in the schemas (Figures \ref{fig:chap2_figureS15} and \ref{fig:chap2_figureS16}).

\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/Figure3.pdf}
    \caption[Comparison of the core (cgMLST) and accessory (agMLST) pairwise Jaccard distances.]{Comparison of the core (\ac{cgMLST}) and accessory (\ac{agMLST}) pairwise Jaccard distances. The pairwise Jaccard distances computed based on chewBBACA 3's allele calling results for the complete datasets (n=16,384 genomes) of \textit{Streptococcus pyogenes}, \textit{Listeria monocytogenes}, and \textit{Salmonella enterica} were compared against the the pairwise distances computed from chewBBACA 2's and pyMLST's results. The regression lines are displayed in red. The number of core or accessory loci determined based on chewBBACA 3’s results are shown in the top-left corner of the plot area. The number of core or accessory loci determined based on chewBBACA 2’s or pyMLST’s results are shown in the bottom-right corner of the plot area.}
    \label{fig:chap2_figure3}
\end{figure*}

Compared to chewBBACA 2, chewBBACA 3 identifies special classifications more accurately (Figures \ref{fig:chap2_figureS17}-\ref{fig:chap2_figureS19} and Table \ref{tab:ch2_tableS13}). The identification of paralogous loci was improved by introducing the \ac{PAMA} classification (Figure \ref{fig:chap2_figureS3}) for \ac{CDSs} that match multiple loci and subdividing the \ac{NIPH} classification into \ac{NIPHEM} and \ac{NIPH} to differentiate between multiple exact matches or a combination of exact and inexact matches (Figure \ref{fig:chap2_figureS2}). chewBBACA 3 displays greater sensitivity for detecting multiple matches, leading to more \ac{NIPH} and \ac{NIPHEM} classifications than chewBBACA 2, which, in some cases, would detect a single exact match and fail to identify additional inexact matches. The \ac{PLOT} classification, used by chewBBACA 2 to classify \ac{CDSs} close to contig ends, was subdivided into \ac{PLOT5}, \ac{PLOT3} and \ac{LOTSC} to indicate if a \ac{CDS} is close to the 5'-end, 3'-end, or both (Figure \ref{fig:chap2_figureS1}). New output files include the genomic coordinates for the \ac{CDSs} predicted for all input genomes and relevant classification statistics per genome and locus. The \ac{DNA} sequences of the \ac{CDSs} assigned special classifications or not classified can be stored in FASTA files by providing the \textit{-{}-output-missing} and \textit{-{}-output-unclassified} options, respectively. These changes improve the granularity of the results to facilitate downstream analyses, such as identifying low-quality inputs, paralogous loci, more divergent alleles, and potential new loci to add to schemas.

Another known issue when using \ac{wg/cgMLST} approaches is that allelic profiles generated with schemas that do not share the same allele nomenclature are not directly comparable. To enable the comparison of results generated with different schemas, chewBBACA 3 includes the \textit{-{}-hash-profiles} option that hashes allele sequences to generate hashed allelic profiles. Since the same allele sequence will always result in the same hash value, the allelic profiles can be compared independently of the nomenclatures used by the schemas allowing also greater data privacy. chewBBACA 3 uses the SHA256 algorithm included in Python’s \textit{hashlib} module by default, but users can select any of the algorithms included in that module or the \textit{zlib} module.

\subsection{Interactive reports for comprehensive wg/cgMLST schema and allele call results analyses} \label{ssec:ch2_results_discussion_ssec4}

The schemas and allele calling results generated by chewBBACA 3 can be a source of valuable data for in-depth analyses that explore the loci diversity captured by a schema and the relatedness of strains of interest. We developed modules that enable a local, scalable and comprehensive analysis of \ac{wg/cgMLST} schemas and results through interactive reports to support users in performing common downstream analyses to more easily reach an informed decision. To showcase the utility of the reports' functionalities, we analysed 264 \textit{S. pyogenes} \textit{emm1} strains, including strains from the recently emerged $M1_{UK}$ and $M1_{DK}$ lineages \citep{lynskey_emergence_2019, johannesen_increase_2023}, and describe how some of the reports’ components can help identify relevant features to distinguish the lineages.

The \textit{SchemaEvaluator} (Figure \ref{fig:chap2_figureS20}) module evaluates \ac{wg/cgMLST} schemas created with chewBBACA or from external sources to create an interactive report with detailed information about the schema composition. This module had been introduced in chewBBACA 2, however it ceased functioning due to dependency issues. The module was reimplemented and expanded in chewBBACA 3. The main page of the report includes charts that allow exploring the number of alleles and the allele size variation per locus. The module accepts a file with loci annotations to facilitate the identification of loci of interest. For example, the annotations determined by the UniprotFinder module (Figure \ref{fig:chap2_figureS21}) for the \textit{S. pyogenes} schema can be added to a data table to identify which schema loci have the lineage-defining \ac{SNPs} of the $M1_{UK}$ (Figure \ref{fig:chap2_figure4_legend}A) and $M1_{DK}$ lineages. Another data table displays the results of the allele integrity analysis, which identifies classes of invalid alleles per locus (e.g. incomplete \ac{CDSs}, presence of ambiguous bases, absence of start and stop codons, in-frame stop codons, and minimum and locus-specific size thresholds). This can be used to identify problematic loci or loci with unusual variability of size.

\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,height=0.92\textheight]{figures/chapter 2/Figure4.pdf}
    \label{fig:chap2_figure4}
\end{figure*}
\vspace*{-6mm}
\begin{center}
    \emph{(Caption on next page.)}
\end{center}
\begin{figure*}[h!]
    \caption[Report components generated for the analysis of the \textit{S. pyogenes} schema and lineage strains.]{Report components generated for the analysis of the \textit{S. pyogenes} schema and lineage strains. (A) Datatable component of the report generated by the \textit{SchemaEvaluator} module including the annotations determined by the \textit{UniprotFinder} module for 12 schema loci containing lineage-defining \ac{SNPs} for the $M1_{UK}$ lineage. (B) Component of the \textit{SchemaEvaluator} module including a \ac{MSA} of the \textit{rofA} translated alleles identified in the MGAS5005 reference strain (allele 80) and the $M1_{UK}$ strains (alleles 88, 283, and 308). Two amino acid differences caused by two \ac{SNPs} in the \textit{rofA} alleles of the $M1_{UK}$ strains are highlighted in red. (C) Component of the \textit{AlleleCallEvaluator} module including a \ac{NJ} tree computed with FastTree from the core loci \ac{MSA}. The groups of strains belonging to the $M1_{UK}$ (light blue), $M1_{inter}$ (light orange), and $M1_{DK}$ (dark blue) lineages are highlighted. The full reports are available on Zenodo \citep{mamede_supplementary_2025}.}\label{fig:chap2_figure4_legend}
\end{figure*}

The \textit{-{}-loci-reports} option provides a more detailed analysis of each locus through dedicated locus pages, accessible by clicking on the loci identifiers in the main report data tables. Each locus page contains charts for the allele size distribution, sequence size per allele and number of \ac{DNA} alleles for each distinct protein. A \ac{MSA} computed with MAFFT \citep{katoh_mafft_2013} for the translated alleles allows identifying shared regions and differences caused by point mutations or indels. For example, the non-synonymous effect of two \ac{SNPs} in the \textit{rofA} gene used to define the $M1_{UK}$ lineage can be identified using the \ac{MSA} by comparing the reference allele with those identified in $M1_{UK}$ strains (Figure \ref{fig:chap2_figure4_legend}B). The guide tree created by MAFFT is displayed with Phylocanvas.gl \citep{abudahab_phylocanvasgl_2021} to help identify groups of similar or divergent alleles. To provide a convenient way to identify and copy the \ac{DNA} and protein sequences of the alleles, users can use the \textit{-{}-add-sequences} option, which adds code editor components containing the \ac{DNA} and protein sequences to each locus’ page.

A report with a detailed analysis of the allele calling results is obtained by running the \textit{AlleleCallEvaluator} module (Figure \ref{fig:chap2_figureS22}). The report includes data tables with summary statistics and bar charts with the classification counts per strain and locus to explore the classification results and aid in identifying low-quality genomes (e.g. misassembled or contaminated genomes) and problematic loci (e.g. loci with a high number of special classifications). An interactive analysis of loci presence-absence is performed through a heatmap component that enables identifying the set of core loci or loci specific to certain groups of strains. Similar strains can be identified through another heatmap component that displays the matrix of pairwise core allelic distances and enables searching for similar strains based on a distance threshold. The last component in the report displays a \ac{NJ} tree computed with FastTree 2 \citep{price_fasttree_2010} from the core loci \ac{MSA}. This component allows exploring phylogenetic relationships to identify groups of similar strains. For instance, the \ac{NJ} tree from the analysis of the \textit{S. pyogenes} strains allows identifying the groups of strains corresponding to each lineage of the M1 group (Figure \ref{fig:chap2_figure4_legend}C).

The reports' components include features to sort, select, search, and export data in tabular format, in the case of data tables, or as \ac{SVG} files, in the case of charts or trees. Some files necessary to create the components, such as the ones containing the matrix of pairwise core allelic distances and the core loci \ac{MSA}, are provided in the report's folder to allow users to perform custom analyses if desired. The reports are easily shared by simply compressing the report's folder and sharing the resulting archive. The interactive reports created with the \textit{SchemaEvaluator} and \textit{AlleleCallEvaluator} modules for the analysis of the \textit{S. pyogenes} strains are available on Zenodo \citep{mamede_supplementary_2025}.

\section{Conclusions} \label{sec:ch2_conclusions}

chewBBACA 3 constitutes an efficient, scalable, and comprehensive solution for \ac{wg/cgMLST}. The options it provides for schema setup enable users to quickly create schemas from larger collections of genome assemblies or \ac{CDS} data to capture more of the diversity of a bacterial species, or to adapt or import existing schemas created in other platforms or available in Chewie-NS to promote interoperability. The combination of alignment-based and alignment-free approaches allow for efficient and accurate allele calling, making it suitable for integration into workflows that process sample batches of any size, from sequential processing of single samples to vast genome collections for species-level population analyses. chewBBACA 3 classifies more schema loci and \ac{CDSs} than the compared methods, potentially providing superior strain discrimination for surveillance and outbreak investigation. The high level of agreement with chewBBACA 2's results, while providing expanded classifications and richer results, facilitates the transition to the latest chewBBACA version. Comparisons with other \ac{wg/cgMLST} methods should take into account that algorithmic differences between methods, parameter values, and input data quality can greatly affect the resolution and accuracy of the results, which might hinder results comparison and in some cases even lead to fundamentally different conclusions. The reports for schema and allele call evaluation allow a comprehensive and local analysis of locus diversity and strain similarity, enabling scalable and private analyses of the results and reducing the need to combine several tools or develop custom solutions to more fully explore the potential of \ac{wg/cgMLST} schemas. The integration of chewBBACA 3 into \ac{wg/cgMLST} workflows will help to further democratize \ac{wg/cgMLST} by providing broader access to large-scale and detailed analyses to perform focused population studies or facilitate reaching an informed decision in outbreak or transmission investigations.

\section{Methods} \label{sec:ch2_methods}

\subsection{Download and selection of complete and draft genome assemblies} \label{ssec:ch2_methods_ssec1}

Complete and draft genome assemblies annotated as \textit{Streptococcus pyogenes}, \textit{Listeria monocytogenes} and \textit{Salmonella enterica} were downloaded with the \ac{NCBI} Datasets command-line tools v16.12.0 \citep{oleary_exploring_2024} on September 9, 2023. The complete genomes were downloaded from the \ac{NCBI} RefSeq database \citep{sayers_database_2022} using the \textit{–assembly-source “RefSeq”} and \textit{–assembly-level complete} options. The draft genome assemblies were downloaded from the \ac{NCBI} GenBank database \citep{sayers_database_2022} using the \textit{–assembly-source “GenBank”} option. The \textit{–exclude-atypical} and \textit{–mag exclude} options were used in both cases. The number of draft genome assemblies for \textit{S. pyogenes} available from GenBank was insufficient to create the complete dataset (n=16384) for the benchmark. Due to that, draft genome assemblies annotated as \textit{Streptococcus pyogenes} were also downloaded from a collection of 661K genomes available on the \ac{ENA} \citep{blackwell_exploring_2021}. MLST v2.23.0 \citep{jolley_bigsdb_2010, seemann_mlst_nodate} was used to determine the \ac{ST} for all assemblies. Assemblies without a known \ac{ST} or assigned an \ac{ST} from a different species, indicating possible misannotation, were excluded. A custom Python script was also used to filter out assemblies based on a maximum number of contigs of 100, a maximum number of ambiguous bases of 1000, and a minimum and maximum genome size. The minimum and maximum genome size values were defined based on the \textit{min\_ungapped\_length} and \textit{max\_ungapped\_length} values in the “species\_genome\_size.txt” file available on \ac{NCBI}’s FTP on September 9, 2023 (\url{https://ftp.ncbi.nlm.nih.gov/genomes/ASSEMBLY_REPORTS/}) \citep{sayers_database_2022}.

\subsection{Dataset creation} \label{ssec:ch2_methods_ssec2}

The selected draft genome assemblies were subsampled to create datasets to evaluate the performance of chewBBACA 3, chewBBACA 2 and pyMLST. The pairwise \ac{ANI} distances for each species’ selected draft genomes were computed with Skani v0.2.1 \citep{shaw_fast_2023}. To factor in the aligned genome fraction, weighted \ac{ANI} values were computed by multiplying the \ac{ANI} values by the mean of the query and reference aligned fractions. The weighted \ac{ANI} values were ordered to select a set of 16,384 genomes that maximized the average pairwise distance. Smaller datasets were created by randomly sampling this dataset, starting by selecting 1 genome and doubling the dataset size until reaching a dataset size of 8,192. Five replicates were created for each dataset size. The complete datasets with 16,384 genomes were compressed with AGC v3.0 \citep{deorowicz_agc_2023} to allow efficient storage and fast genome retrieval based on lists of genome identifiers.

\subsection{Creation of wg/cgMLST schemas} \label{ssec:ch2_methods_ssec3}

A total of 260, 309 and 1,326 complete genomes for \textit{Streptococcus pyogenes}, \textit{Listeria monocytogenes} and \textit{Salmonella enterica}, respectively, were selected for schema creation. \ac{wgMLST} schema seeds were created with the \textit{CreateSchema} module available in chewBBACA v3.3.6 and compared against the schema seeds created by the previous \textit{CreateSchema} implementation, available in chewBBACA v2.6.0 \citep{silva_chewbbaca_2018}. The schema creation processes used a minimum sequence length value of 0 (\textit{-{}-l 0}) and the Prodigal \citep{hyatt_prodigal_2010} training files bundled with chewBBACA. The schema seeds created by both versions were compared based on a \ac{BSR} $\geq0.6$ and a proportion of shared minimizers $\geq0.9$ to determine sets of loci shared by the schema seeds created with both versions. Schema seeds created with chewBBACA v3.3.0 were populated with the alleles identified in the complete genomes through allele calling. The results of the allele calling were used to determine the set of core loci with the \textit{ExtractCgMLST} module based on a loci presence threshold of 1 (\textit{-{}-t 1}) and create the \ac{cgMLST} schemas used to evaluate the allele calling performance. The \ac{cgMLST} schemas were adapted with the \textit{PrepExternalSchema} module implemented in chewBBACA v2.8.5 to create the \ac{cgMLST} schemas for that version. To create equivalent databases for pyMLST \citep{biguenet_introduction_2023}, multi-FASTA files with the first representative allele for each locus in the \ac{cgMLST} schemas were passed to the \ac{wgMLST} create command. The \ac{wgMLST} add command was used to add each complete genome to the pyMLST databases.

\subsection{External schema adaptation} \label{ssec:ch2_methods_ssec4}

The \ac{cgMLST} schemas for \textit{S. pyogenes}, \textit{L. monocytogenes} and \textit{S. enterica} available on the cgMLST.org server \citep{noauthor_cgmlstorg_nodate} were downloaded on July 4, 2024. These schemas were adapted with the \textit{PrepExternalSchema} module available in chewBBACA v3.3.6 and compared against the schemas adapted with the previous \textit{PrepExternalSchema} implementation, available in chewBBACA v2.0.17.2. The representativeness of the set of representative alleles selected by the \textit{PrepExternalSchema} module was measured by aligning the representative alleles selected for each locus against all valid locus alleles based on a \ac{BSR} $\geq0.6$.

\subsection{Evaluation of the allele calling results} \label{ssec:ch2_methods_ssec5}

The \ac{cgMLST} schemas and datasets containing between 1 and 16,384 draft genome assemblies were used to evaluate the allele calling performance of chewBBACA v3.3.3, chewBBACA v2.8.5 and pyMLST v2.1.5. The number of distinct \ac{CDSs} per dataset was computed based on the \ac{CDSs} predicted by Pyrodigal v3.0.0. Runtime, peak memory usage, and the comprehensiveness of the allele calling were evaluated for all datasets. The allelic profiles for the strains classified by pyMLST were extracted from the databases with the \textit{wgMLST mlst} command and converted to the format used by chewBBACA with a custom script. The allelic profiles were masked to remove the \textit{INF-} prefix from inferred alleles and to substitute all special classifications or missing values by 0. The core loci were defined with the \textit{ExtractCgMLST} module based on the complete datasets' results and a loci presence threshold of 0.95. Loci below this threshold were considered to be part of the accessory genome. The pairwise Jaccard and allelic distances were computed with a custom script based on the masked allelic profiles. The proportion of classified \ac{CDSs} and identified loci are based on the total number of \ac{CDSs} predicted by Pyrodigal and on the total number of loci in each schema, respectively.

\subsection{Download and analysis of \textit{S. pyogenes} \textit{emm1} strains} \label{ssec:ch2_methods_ssec6}

The genome assemblies and metadata for the \textit{S. pyogenes} strains belonging to each lineage were recovered from previous studies \citep{lynskey_emergence_2019, johannesen_increase_2023, friaes_annotated_2022}. The schema loci containing the lineage-defining \ac{SNPs} were identified using \ac{BLASTp} to align the translated \ac{CDSs} from the MGAS5005 reference genome \citep{sumby_evolutionary_2005}, with RefSeq accession number \textit{GCF\_000011765.3}, against the translated schema alleles.

\subsection{Runtime and peak memory usage measurement} \label{ssec:ch2_methods_ssec7}

Runtime and peak memory usage were measured with the GNU time command on a desktop computer with an Intel® Core™ i7-4790 CPU, 32GB 1600 MT/s RAM, and a 1TB Samsung SSD 870 QVO. Any analysis that evaluated runtime and peak memory usage used 6 CPU cores to run chewBBACA 3 and chewBBACA 2 and 1 CPU core for pyMLST because the latter cannot use multiple cores.

\section{Availability and requirements} \label{sec:ch2_availability_and_requirements}

\noindent Project name: chewBBACA 3.\\
Project home page: \url{https://github.com/B-UMMI/chewBBACA}\\
Project documentation: \url{https://chewbbaca.readthedocs.io/en/latest/index.html}\\
Operating system(s): Linux and macOS.\\
Programming language: Python >= 3.8\\
Other requirements: BLAST+ >= 2.9.0, pyrodigal>=3.0.0, numpy~=1.24.3, scipy~=1.10.1, biopython>=1.79, plotly>=5.8.0, SPARQLWrapper>=2.0.0, requests>=2.27.1, pandas>=1.5.1\\
License: GPL-3.0\\
Any restrictions to use by non-academics: None.

\section{Declarations} \label{sec:ch2_declarations}

\subsection{Ethics approval and consent to participate} \label{ssec:ch2_declarations_ssec1}

\noindent Not applicable.

\subsection{Consent for publication} \label{ssec:ch2_declarations_ssec2}

\noindent Not applicable.

\subsection{Availability of data and materials} \label{ssec:ch2_declarations_ssec3}

The datasets, schemas and databases created and used with chewBBACA 3, chewBBACA 2, and pyMLST, and all results generated for each section are available on Zenodo (\url{https://doi.org/10.5281/zenodo.14637859}) \citep{mamede_supplementary_2025}. The supplementary figures and tables are included in the supplementary data.

\subsection{Competing interests} \label{ssec:ch2_declarations_ssec4}

MR received honoraria for serving on the speakers bureau of Pfizer and Merck Sharp and Dohme and for serving in expert panels of GlaxoSmithKline and Merck Sharp and Dohme. All other authors declare they have no competing interests.

\subsection{Funding} \label{ssec:ch2_declarations_ssec5}

This work was partly supported by the ISIDORe project (funding from the European Union’s Horizon Europe Research \& Innovation Programme, Grant Agreement no. 101046133). RM was supported by the \ac{FCT} (grant 2020.08493.BD).

\subsection{Author’s contributions} \label{ssec:ch2_declarations_ssec6}

All authors contributed to the design of the tool. RM implemented, tested, and benchmarked the tool. PVC contributed to the implementation of the tool. RM and MR wrote the manuscript. All authors read, revised and approved the final manuscript.

\newpage

\section{Supplemental Material} \label{sec:ch2_supplemental_material}

\subsection{Supplemental Figures} \label{ssec:ch2_supplemental_figures}

\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS1.pdf}
    \caption[PLOT5, PLOT3 and LOTSC classifications.]{\ac{PLOT5}, \ac{PLOT3} and \ac{LOTSC} classifications. The \ac{PLOT3}, \ac{PLOT5} and \ac{LOTSC} classifications are related to the position of \ac{CDSs} in the genomic contigs. \ac{PLOT5} and \ac{PLOT3} - a CDS is classified as \ac{PLOT5} or \ac{PLOT3} if it is close to the contig 5’- or 3’-end and if the unaligned portion of the matched representative allele exceeds the contig end. \ac{LOTSC} - a \ac{CDS} is classified as \ac{LOTSC} if the matched representative allele is bigger than the contig containing the \ac{CDS}.}
    \label{fig:chap2_figureS1}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS2.pdf}
    \caption[NIPH and NIPHEM classifications.]{\ac{NIPH} and \ac{NIPHEM} classifications. The \ac{NIPH} and \ac{NIPHEM} classifications are assigned when multiple \ac{CDSs} from the same genome match the same schema locus. \ac{NIPH} - assigned when multiple \ac{CDSs} from the same genome match a single locus. \ac{NIPHEM} - assigned when multiple \ac{CDSs} from the same genome are exact matches to alleles of a single locus.}
    \label{fig:chap2_figureS2}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS3.pdf}
    \caption[PAMA classification.]{\ac{PAMA} classification. The \ac{PAMA} classification is assigned when a single \ac{CDS} from a genome matches multiple schema loci.}
    \label{fig:chap2_figureS3}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS4.pdf}
    \caption[ASM and ALM classifications.]{\ac{ASM} and \ac{ALM} classifications. The \ac{ASM} and \ac{ALM} classifications are assigned when the size of a \ac{CDS} that matches a schema locus is below or above the locus size variation interval, respectively. The default behaviour is to assign these classifications to alleles that are 20\% shorter or longer than the locus allele size mode.}
    \label{fig:chap2_figureS4}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS5.pdf}
    \caption[Diagram of the \textit{CreateSchema} module.]{Diagram of the \textit{CreateSchema} module. The \textit{CreateSchema} module creates a schema seed based on a set of FASTA files with genome assemblies or \ac{CDSs}. If genome assemblies are given, the process starts by predicting \ac{CDSs} for each genome using Pyrodigal. The \ac{CDSs} identified in the input files are deduplicated and translated, followed by a second deduplication step to determine the set of distinct translated \ac{CDSs}. The distinct translated \ac{CDSs} are clustered based on the proportion of minimizers shared with representative \ac{CDSs}. The largest or one of the largest \ac{CDSs} is selected as the first representative \ac{CDS}. New representative \ac{CDSs} are selected when \ac{CDSs} share a low proportion (<0.2) of minimizers with any of the chosen representative \ac{CDSs}. Non-representative \ac{CDSs} that share a proportion of minimizers $\geq0.9$ with the cluster representative are considered to correspond to the same locus and are excluded from the analysis. The proportion of shared minimizers between non-representative \ac{CDSs} is determined to exclude \ac{CDSs} sharing a proportion of minimizers $\geq0.9$ with larger \ac{CDSs}. Intracluster and intercluster alignment with \ac{BLASTp} enable identifying and excluding \ac{CDSs} similar to representative or larger non-representative \ac{CDSs} based on a \ac{BSR} $\geq0.6$. Each remaining \ac{CDS} is considered to be an allele of a distinct locus. The process ends by creating a schema seed, which includes one FASTA file containing a single representative allele per distinct locus identified in the analysis. Green document icons represent input FASTA files and output files. Grey rectangle icons represent analysis steps. Diamond icons represent conditional statements, with green arrows used when the condition is met and red dashed arrows otherwise. The blue cylinder icon represents the schema seed created by the \textit{CreateSchema} module.}
    \label{fig:chap2_figureS5}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS6.pdf}
    \caption[Diagram of the \textit{AlleleCall} module.]{Diagram of the \textit{AlleleCall} module. The \textit{AlleleCall} module determines the allelic profiles for strains of interest. The process accepts FASTA files with genome assemblies or \ac{CDSs}. If genome assemblies are given, the process starts by predicting \ac{CDSs} for each genome using Pyrodigal. The \ac{CDSs} identified in the input files are deduplicated and compared against the schema alleles to find and classify exact matches at the \ac{DNA} level. If the process runs in mode 1, the results are evaluated to write the output files and exit. Otherwise, the \ac{CDSs} that do not match any schema alleles at the \ac{DNA} level are translated and matched against the translated schema alleles to find exact matches at the protein level. If the process runs in mode 2, the results are evaluated to write the output files, add new alleles to the schema and exit. Otherwise, the \ac{CDSs} not classified through exact matching are compared against the schema representative alleles through minimizer-based clustering to identify \ac{CDSs} that share a proportion of minimizers $\geq0.2$ with the representative alleles. Each cluster's representative allele is aligned against the clustered \ac{CDSs} with \ac{BLASTp} to classify \ac{CDSs} based on the defined \ac{BSR} value plus 0.1. At this point, if the process runs in mode 3, the results are evaluated to write the output files, add new alleles to the schema and exit. Otherwise, the representative alleles are aligned against the remaining unclassified \ac{CDSs} to classify them based on the defined \ac{BSR} value and identify new representative alleles whose \ac{BSR} is not above the defined \ac{BSR} value plus 0.1. If the process finds new representative alleles, it aligns them against the unclassified \ac{CDSs} to find new matches. This process repeats until no new representative alleles are identified. When no new representative alleles are found, the process evaluates the results to create the output files, add new alleles to the schema, and exit. Green document icons represent input FASTA files and output files. Grey rectangle icons represent analysis steps. Diamond icons represent conditional statements, with green arrows used when the condition is met and red dashed arrows otherwise. The blue cylinder icon represents a schema.}
    \label{fig:chap2_figureS6}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=0.9\textwidth]{figures/chapter 2/FigureS7.pdf}
    \caption[Sequence hashing and modified polyline encoding.]{Sequence hashing and modified polyline encoding. (A) Each distinct \ac{CDS} identified in the input genomes is hashed with the SHA-256 algorithm implemented in Python's \textit{hashlib} library. The hash digest is obtained through the \textit{hexdigest} method and mapped to the list of integer identifiers for the genomes containing the \ac{CDS} encoded with modified polyline encoding. (B) After sequence translation and deduplication, each distinct translated \ac{CDS} is hashed with the SHA-256 algorithm and the hash digest is mapped against lists with pairs of protein and genome identifiers used to identify each distinct \ac{CDS} coding for the protein encoded with modified polyline encoding. The modified polyline encoding is applied to reduce the memory used to retain the data in-memory during the process, drastically reducing peak memory usage when processing large datasets. The Python dictionaries created to map the hashes to the lists of identifiers allow quick identification and classification of exact and inexact matches.}
    \label{fig:chap2_figureS7}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS8.pdf}
    \caption[Diagram of the \textit{PrepExternalSchema} module.]{Diagram of the \textit{PrepExternalSchema} module. The \textit{PrepExternalSchema} module adapts schemas created with other \ac{wg/cgMLST} tools or available on external platforms for usage with chewBBACA 3. The process starts by validating and translating the alleles in the external schema. Incomplete (i.e. size not multiple of 3) and invalid (i.e. missing the start or stop codons, or containing in-frame stop codons) alleles, alleles containing ambiguous bases or smaller than the specified minimum length value, are excluded. For each locus that has valid alleles, the process selects the largest or one of the largest alleles as the first representative allele. The representative is aligned against the locus' alleles with \ac{BLASTp} to compute the \ac{BSR} for each alignment. If all the \ac{BSR} values are above the specified \ac{BSR} plus 0.1, it is considered that the representative allele can adequately capture the diversity of the locus. Otherwise, new representative alleles are selected from those with a \ac{BSR} above the specified \ac{BSR} but below that value plus 0.1 to align against the locus' alleles and determine if the set of representative alleles selected captures the locus diversity adequately. Representative selection is repeated until all locus' alleles have a \ac{BSR} above the specified value plus 0.1 with at least one of the selected representative alleles. The valid and selected representative alleles are written to FASTA files to create a schema compatible with chewBBACA. The list of invalid alleles, the list of loci excluded from the adapted schema due to having no valid alleles, and the number of total alleles and representative alleles per locus in the adapted schema are stored in output files. The green document icons represent output files. Grey rectangle icons represent analysis steps. Diamond icons represent conditional statements, with green arrows used when the condition is met and red dashed arrows otherwise. The blue cylinder icons represent schemas.}
    \label{fig:chap2_figureS8}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS9.pdf}
    \caption[Diagram of the \textit{DownloadSchema} module.]{Diagram of the \textit{DownloadSchema} module. The \textit{DownloadSchema} module imports schemas from Chewie-NS. The process starts by sending a request with species and schema identifiers to Chewie-NS. If the schema exists, the process checks for a compressed and up-to-date version of the schema to download. If the compressed schema in Chewie-NS is for the latest version of the schema, the compressed schema is downloaded and uncompressed to get a ready-to-use schema. Otherwise, the process will send requests to retrieve the FASTA files with the alleles for all loci and determine the representative alleles with the \textit{PrepExternalSchema} module to create the schema locally. Grey rectangle icons represent analysis steps. Diamond icons represent conditional statements, with green arrows used when the condition is met and red dashed arrows otherwise. The blue cylinder icons represent schemas.}
    \label{fig:chap2_figureS9}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS10.pdf}
    \caption[Diagram of the \textit{LoadSchema} module.]{Diagram of the \textit{LoadSchema} module. The \textit{LoadSchema} module uploads local schemas to Chewie-NS. The process starts by requesting the user credentials to ensure that the user has contributor privileges. Only contributors are allowed to upload schemas to Chewie-NS. If the user is a contributor, the process checks if the species identifier provided by the user is valid and if the species is listed in Chewie-NS. After this step, the process reads the schema’s configuration file to validate the schema parameter values and ensure that there is only a single value associated with each parameter. The initial validation steps are followed by the upload of the schema data to Chewie-NS. The process reads the schema description, if the user provided one, or uses the schema name as description. The alleles are translated and annotation terms for the loci are obtained through UniProt’s \ac{SPARQL} endpoint. If the user provides custom loci annotations, the process reads the file provided by the user and adds the custom annotations to the loci annotation data to send to Chewie-NS. After retrieving loci annotations, the process creates the schema in Chewie-NS by sending the schema’s parameter values and the list of file hashes to validate schema files uploaded in subsequent steps. The loci are created and linked to the newly created schema by sending the loci identifiers and annotations to Chewie-NS. The loci FASTA files are compressed and uploaded to Chewie-NS to add the allele sequences to the database and link them to the corresponding loci. The last step in the process uploads the training file in the local schema and associates it to the newly created schema in Chewie-NS. After process completion, Chewie-NS will process the data that was sent to make the schema data and statistics available through the website and the \ac{API}. Grey rectangle icons represent analysis steps. Diamond icons represent conditional statements, with green arrows used when the condition is met and red dashed arrows otherwise. The blue cylinder icon represents a schema.}
    \label{fig:chap2_figureS10}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS11.pdf}
    \caption[Diagram of the \textit{SyncSchema} module.]{Diagram of the \textit{SyncSchema} module. The \textit{SyncSchema} module retrieves new alleles added to remote schemas in Chewie-NS and submits new alleles added to local schemas to update the remote schemas in Chewie-NS. The process starts by reading the schema’s configuration file to get the schema’s parameter values and ensure the values match the ones listed in Chewie-NS. If the user wants to submit new alleles identified locally (-{}-submit), the process will ask for the user credentials to verify if the user has contributor privileges. Before retrieving or uploading new alleles, the process verifies if the last modification date of the local and remote schemas match. If the dates match and the user does not want to submit new local alleles, the process exits. If the dates do not match or the user wants to submit new local alleles, the process retrieves new alleles added to the remote schema since the last modification date and compares them with the alleles in the local schema. If any alleles are exclusive to the local or remote schema, the process creates updated FASTA files with all the alleles and locks the remote schema to ensure that only the current user can modify the remote schema. The process creates files with the data for the new local alleles and sends them to Chewie-NS, waiting for Chewie-NS to insert the new alleles into the database. After allele insertion in Chewie-NS, the process adapts the updated FASTA files with the \textit{PrepExternalSchema} module to update the local schema and ensure that the local and remote allele identifiers match. If the schema was already locked by another user, the process will skip data upload to Chewie-NS and will update the local schema with new alleles retrieved from Chewie-NS. Grey rectangle icons represent analysis steps. Diamond icons represent conditional statements, with green arrows used when the condition is met and red dashed arrows otherwise. The blue cylinder icon represents a schema.}
    \label{fig:chap2_figureS11}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS12.pdf}
    \caption[Diagram of the \textit{ExtractCgMLST} module.]{Diagram of the \textit{ExtractCgMLST} module. The \textit{ExtractCgMLST} module determines the set of core loci based on the allelic profiles determined by the \textit{AlleleCall} module. The process starts by excluding loci and samples from the analysis based on lists of loci and samples provided by the user. This allows users to filter out low-quality samples and problematic loci that would affect the determination of the core genome. The filtered allelic profiles are masked to remove the INF- prefixes from newly inferred alleles and substitute special classifications by 0. The masked profiles are used to compute a loci presence-absence matrix and count the number of special classifications per sample. The presence-absence matrix is also used to determine the set of core loci based on the default loci presence thresholds of 0.9, 0.95 and 1, or based on threshold values specified by the user. The process creates output files with the list of loci and allelic profiles per threshold and creates an \ac{HTML} file with a scatter plot representing the core genome size variation for each threshold. The green document icons represent input and output files. Grey rectangle icons represent analysis steps. Diamond icons represent conditional statements, with green arrows used when the condition is met and red dashed arrows otherwise.}
    \label{fig:chap2_figureS12}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS13.pdf}
    \caption[Runtime and peak memory usage for the four execution modes available in chewBBACA 3.]{Runtime and peak memory usage for the four execution modes available in chewBBACA 3. Runtime and peak memory usage were measured for the allele calling of datasets with 1 to 16384 strains for three bacterial species: \textit{Streptococcus pyogenes}, \textit{Listeria monocytogenes}, and \textit{Salmonella enterica}. The benchmark was performed with five replicates per dataset size, except for the complete dataset (n=16,384 genomes). The values shown are the mean of the replicate values for each dataset. Runtime was measured as the elapsed real time in minutes (logarithmic scale). Peak memory usage was measured as the maximum resident set size in \ac{MB} (logarithmic scale).}
    \label{fig:chap2_figureS13}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS14.pdf}
    \caption[Pairwise allelic distances differences.]{Pairwise allelic distances differences. The pairwise distances differences at the core-genome (\ac{cgMLST}) and accessory-genome (\ac{agMLST}) levels were computed by subtracting the allelic distance matrices computed based on chewBBACA 2's and pyMLST's results from the allelic distance matrices computed from chewBBACA 3's results for the complete datasets (n=16,384 genomes). A positive value represents a greater difference with chewBBACA 3 and a negative value a smaller difference with chewBBACA 3 than with the comparator. The zero line in each plot is highlighted in red.}
    \label{fig:chap2_figureS14}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS15.pdf}
    \caption[Proportion of CDSs classified per execution mode for each species’ datasets.]{Proportion of \ac{CDSs} classified per execution mode for each species’ datasets. The proportion of classified \ac{CDSs} corresponds to the number of \ac{CDSs} classified by each execution mode divided by the total number of \ac{CDSs} predicted for each strain by Pyrodigal. The benchmark was performed with five replicates per dataset size, except for the complete dataset (n=16,384 genomes).}
    \label{fig:chap2_figureS15}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS16.pdf}
    \caption[Proportion of schema loci classified per execution mode for each species’ datasets.]{Proportion of schema loci classified per execution mode for each species’ datasets. The proportion of classified loci corresponds to the number of schema loci identified by each execution mode divided by the total number of schema loci. The benchmark was performed with five replicates per dataset size, except for the complete dataset (n=16,384 genomes).}
    \label{fig:chap2_figureS16}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS17.pdf}
    \caption[Classifications counts for the complete dataset (n=16,384 genomes) of \textit{S. pyogenes} per tool.]{Classifications counts for the complete dataset (n=16,384 genomes) of \textit{S. pyogenes} per tool. Each row displays the counts for the special classifications that are equivalent between tools. The x-axis labels show the names of the classifications and the number of genomes with a count above zero inside the parentheses (i.e. genomes with a count of zero for any of the classifications are not included in the plotted values). For pyMLST, the loci with a single matching \ac{CDS} were converted to \ac{EXC} and the loci with multiple matches were converted to \ac{NIPHEM}. The plot is not shown if the tool does not determine a special classification equivalent to the ones displayed in the row.}
    \label{fig:chap2_figureS17}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS18.pdf}
    \caption[Classifications counts for the complete dataset (n=16,384 genomes) of \textit{L. monocytogenes} per tool.]{Classifications counts for the complete dataset (n=16,384 genomes) of \textit{L. monocytogenes} per tool. Each row displays the counts for the special classifications that are equivalent between tools. The x-axis labels show the names of the classifications and the number of genomes with a count above zero inside the parentheses (i.e. genomes with a count of zero for any of the classifications are not included in the plotted values). For pyMLST, the loci with a single matching \ac{CDS} were converted to \ac{EXC} and the loci with multiple matches were converted to \ac{NIPHEM}. The plot is not shown if the tool does not determine a special classification equivalent to the ones displayed in the row.}
    \label{fig:chap2_figureS18}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS19.pdf}
    \caption[Classifications counts for the complete dataset (n=16,384 genomes) of \textit{S. enterica} per tool.]{Classifications counts for the complete dataset (n=16,384 genomes) of \textit{S. enterica} per tool. Each row displays the counts for the special classifications that are equivalent between tools. The x-axis labels show the names of the classifications and the number of genomes with a count above zero inside the parentheses (i.e. genomes with a count of zero for any of the classifications are not included in the plotted values). For pyMLST, the loci with a single matching \ac{CDS} were converted to \ac{EXC} and the loci with multiple matches were converted to \ac{NIPHEM}. The plot is not shown if the tool does not determine a special classification equivalent to the ones displayed in the row.}
    \label{fig:chap2_figureS19}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS20.pdf}
    \caption[Diagram of the \textit{SchemaEvaluator} module.]{Diagram of the \textit{SchemaEvaluator} module. The \textit{SchemaEvaluator} module analyses a schema to create a report that allows users to explore schema structure and loci diversity interactively. The process starts by computing schema statistics, such as the number of loci and alleles, and loci statistics, such as the number of alleles, allele size statistics, and the number of valid and invalid alleles (e.g. alleles that cannot be translated due to being incomplete, containing ambiguous bases, in-frame stop codons, etc.). The schema and loci statistics are included in interactive data tables and charts on the main page of the \ac{HTML} report. Loci annotations are imported and included in the main page of the report if provided. If the \textit{-{}-loci-reports} option is provided, the process performs a detailed analysis of each locus to add a separate locus page to the \ac{HTML} report for each locus. Loci data is analyzed in greater detail to get more detailed statistics per locus. If the \textit{-{}-add-sequences} option is provided, the allele \ac{DNA} sequences are imported and translated to add \ac{DNA} and protein sequences to code editors on the locus page, which facilitates identifying and manipulating alleles of interest. Additionally, the process computes a \ac{MSA} for each locus at the protein level with MAFFT to display the \ac{MSA} and MAFFT's guide tree on interactive components. The \ac{MSA} and guide tree are not displayed if the \textit{-{}-light} option is provided. The green document icons represent output files. Grey rectangle icons represent analysis steps. Diamond icons represent conditional statements, with green arrows used when the condition is met and red dashed arrows otherwise. The blue cylinder icon represents a schema.}
    \label{fig:chap2_figureS20}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS21.pdf}
    \caption[Diagram of the \textit{UniprotFinder} module.]{Diagram of the \textit{UniprotFinder} module. The \textit{UniprotFinder} module determines annotations for schema loci. The module offers two options to determine annotations: aligning against UniProt's reference proteomes and exact matching through UniProt's \ac{SPARQL} endpoint. Users must provide at least one valid taxon name to annotate based on the reference proteomes. The process downloads the list of reference proteomes and searches for proteomes for the specified taxa. If there are any proteomes for the specified taxa, they are downloaded, and the loci representative alleles are aligned against the reference proteomes so annotations can be selected based on the \ac{BSR}. The process searches for annotations through UniProt's \ac{SPARQL} endpoint by creating queries including the loci alleles and submitting requests to the endpoint. If an allele matches any protein in UniProt, the annotation terms are extracted from the results. The process tries to select the most informative annotation terms. The annotation terms found through both options are merged to create a single annotations table. If the user provides a \ac{TSV} file with additional loci data, such as the file with \ac{CDS} coordinates created by the \textit{CreateSchema} and \textit{AlleleCall} modules, the process will add the data in that file to the annotations table. The green document icon represents the output file. Grey rectangle icons represent analysis steps. Diamond icons represent conditional statements, with green arrows used when the condition is met and red dashed arrows otherwise. The blue cylinder icon represents a schema.}
    \label{fig:chap2_figureS21}
\end{figure*}

\newpage
\begin{figure*}[h!]
    \centering
    \includegraphics[angle=0,width=\textwidth]{figures/chapter 2/FigureS22.pdf}
    \caption[Diagram of the \textit{AlleleCallEvaluator} module.]{Diagram of the \textit{AlleleCallEvaluator} module. The \textit{AlleleCallEvaluator} module analyses allele calling results to create a report that allows users to explore results interactively. The process starts by importing and computing sample and loci statistics based on the allele calling results. The sample and loci statistics are included in interactive data tables and charts on the main page of the \ac{HTML} report. Loci annotations are imported and included in the main page of the report if provided. If the \textit{-{}-light} option is provided, the process does not add more information to the report. Otherwise, the allelic profiles are imported and masked to remove \textit{INF-} prefixes and substitute special classifications by 0. The masked profiles serve as the basis for computing a \ac{PA} matrix, enabling the determination of the set of loci that constitute the core genome. The profile data for the core loci are used to compute a matrix of allelic distances. The core loci alleles identified per strain and locus are imported to compute the \ac{cgMLST} alignment that FastTree uses to compute a \ac{NJ} tree. The \ac{PA} and distance matrices and \ac{NJ} tree data are included in the report to be displayed and explored interactively. The green document icons represent input and output files. Grey rectangle icons represent analysis steps. Diamond icons represent conditional statements, with green arrows used when the condition is met and red dashed arrows otherwise. The blue cylinder icon represents a schema.}
    \label{fig:chap2_figureS22}
\end{figure*}

\subsection{Supplemental Tables} \label{ssec:ch2_supplemental_tables}

\newpage
\begin{landscape}
\vspace*{\fill}
\input{tables/chapter_2/suptable1}
\vspace*{\fill}
\end{landscape}

\newpage
\begin{landscape}
\vspace*{\fill}
\input{tables/chapter_2/suptable2}
\vspace*{\fill}
\end{landscape}

\newpage
\begin{landscape}
\vspace*{\fill}
\input{tables/chapter_2/suptable3}
\vspace*{\fill}
\end{landscape}

\newpage
\begin{landscape}
\vspace*{\fill}
\input{tables/chapter_2/suptable4}
\vspace*{\fill}
\end{landscape}

\newpage
\begin{landscape}
\vspace*{\fill}
\input{tables/chapter_2/suptable5}
\vspace*{\fill}
\end{landscape}

\newpage
\begin{landscape}
\vspace*{\fill}
\input{tables/chapter_2/suptable6}
\vspace*{\fill}
\end{landscape}

\newpage
\begin{landscape}
\vspace*{\fill}
\input{tables/chapter_2/suptable7}
\vspace*{\fill}
\end{landscape}

\newpage
\begin{landscape}
\vspace*{\fill}
\input{tables/chapter_2/suptable8}
\vspace*{\fill}
\end{landscape}

\newpage
\begin{landscape}
\vspace*{\fill}
\input{tables/chapter_2/suptable9}
\vspace*{\fill}
\end{landscape}

\newpage
\begin{landscape}
\vspace*{\fill}
\input{tables/chapter_2/suptable10}
\vspace*{\fill}
\end{landscape}

\newpage
\begin{landscape}
\vspace*{\fill}
\input{tables/chapter_2/suptable11}
\vspace*{\fill}
\end{landscape}

\newpage
\begin{landscape}
\vspace*{\fill}
\input{tables/chapter_2/suptable12}
\vspace*{\fill}
\end{landscape}

\newpage
\begin{landscape}
\vspace*{\fill}
\input{tables/chapter_2/suptable13}
\vspace*{\fill}
\end{landscape}
